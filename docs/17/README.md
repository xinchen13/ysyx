# 流水线处理器
通过icache提升了NPC的指令供给能力, 虽然面积预算很有限, 但添加icache还是明显提升了NPC的总体性能表现. 剩下的优化方向包括提升数据供给能力和提升计算效率.

## 评估dcache的理想收益 & 通过cachesim评估dcache的预期性能表现
应该会发现, 在剩余的面积预算下, 我们很难通过dcache来有效提升NPC的数据供给能力. 因此, 把剩余的面积用在提升计算效率, 是更科学的决策. 目前的NPC是多周期的, 这意味着NPC每经过若干个周期才能执行一条指令. 如果能提升NPC执行指令的吞吐, 就可以提升其计算效率. 流水线作为一种指令级并行技术, 可以有效提升NPC执行指令的吞吐

## 评估提升计算效率的理想收益
根据性能计数器可以来估算流水线技术的理想收益: 假设除访存指令之外, NPC每个周期都可以执行一条指令, 尝试估算在当前icache缺失情况的条件下, 此时NPC的理想加速比能到多少?

## 流水线的基本原理
指令流水线: 处理器用流水线方式来执行指令, 把指令执行的过程分为若干个阶段, 让每个部件处理其中一个阶段, 并让这些部件保持工作状态, 可以连续处理不同指令的同一个阶段, 使得从总体上来看, 每个周期都有一条指令完成执行, 从而提升处理器的吞吐. 我们可以对几种处理器的性能进行简单的分析评估. 假设将处理器的工作分为取指, 译码, 执行, 访存, 写回这5个阶段, 它们的逻辑延迟都是1ns, 且先不考虑取指和访存的延迟.

- 单周期处理器: 阶段间无寄存器, 因此关键路径为5ns, 频率为200MHz. 其中, 一条指令需要执行1周期, 即5ns; 每1周期执行1条指令, 即`IPC = 1`
- 多周期处理器: 阶段间有寄存器, 因此关键路径为1ns, 频率为1000MHz. 其中, 一条指令需要执行5周期, 即5ns; 每5周期执行1条指令, 即`IPC = 0.2`
- 流水线处理器: 阶段间有寄存器, 因此关键路径为1ns, 频率为1000MHz. 其中, 一条指令需要执行5周期, 即5ns; 每1周期执行1条指令, 即`IPC = 1`

虽然指令执行的延迟仍然是5ns, 但流水线具有频率高和IPC高的优势, 这些优势本质上是由指令级并行技术带来的: 流水线处理器的每个周期都在处理5条不同的指令. 当然, 上面只是从理想情况下分析得到的数据. 如果考虑SoC中的访存, IPC就远远没有这么高了; 此外流水线处理器也并不是总能在每个周期都执行5条指令

#### 更长的流水线
上面的例子只将流水线划分成5个阶段. 事实上, 我们可以将流水线划分成更多的阶段, 使得每一个阶段的逻辑更简单, 从而提升处理器整体的频率. 这种流水线称为"超流水"(superpipeline). 例如, 如果能将流水线划分成30级, 按照上面的估算, 理论上频率可以达到6GHz. 但目前的主流高性能处理器一般只会将流水线划分成15级左右, 导致不宜将流水线划分成过多的阶段的因素有(from chatgpt):

- 复杂的控制逻辑： 随着流水线阶段的增加，控制逻辑会变得更加复杂。需要更多的控制信号来协调各个阶段，避免数据冒险、控制冒险等问题。这不仅增加了硬件设计的难度，也可能导致更多的时钟周期浪费
- 数据冒险和转发开销： 多个流水线阶段可能增加了数据冒险的可能性，需要更多的转发机制或前递路径来解决。这些额外的开销可能抵消通过超流水线带来的性能提升。
- 分支预测的困难： 更长的流水线意味着分支预测的正确性变得更加重要，但由于分支可能在流水线的较长阶段内才被识别到，因此分支预测失误的代价会更高。更长的流水线可能导致较大的性能惩罚。
- 处理器的设计和制造成本： 超流水线不仅增加了设计复杂度，也可能增加制造成本。每增加一个阶段，可能都需要更多的管脚、逻辑单元、寄存器等资源，这会增加芯片的面积和功耗

## 流水线的简单实现
首先对 xcore 进行重构, 使得更容易修改成流水线结构:
- 实现一个流水线寄存器模块 `pipe_regs` 代替所有的流水线寄存器模块, 带有 valid-ready 握手功能(能够作为空泡的替代实现, 减少功耗), 并添加 flush 功能
- 添加 id 与 ex, ex 与 lsu 之间的流水线寄存器
- 把 csr 的写入修改到执行 (ex) 阶段

基于握手机制的多周期处理器来实现流水线并不困难, 对于每个阶段的输入in和输出out, 我们只需要正确处理数据和 valid-ready 的关系. 特别地, ifu 无需等待当前指令执行结束, 即可马上取出下一条指令. 故下游模块需要将收到的消息记录到缓冲区中, 防止消息丢失.

特别地, 流水线处理器中会存在一些无法继续执行当前指令的情况, 称为"冒险"(Hazard). 冒险主要分为3类: 结构冒险, 数据冒险和控制冒险. 如果无视冒险强行执行, 将会导致CPU状态机的转移结果与ISA状态机不一致, 表现为指令的执行结果不符合其语义. 因此在流水线设计中, 我们需要检测出冒险, 要么通过硬件设计消除它们, 要么从时间上等待冒险不再发生. 对于后者, 可以通过对 ready 和 valid 添加等待条件来实现

### 结构冒险
结构冒险是指流水线中的不同阶段需要同时访问同一个部件, 但该部件无法支持被多个阶段同时访问. 例如, 在下图所示的指令序列中, 在T4时刻, I1正在LSU中读数据, I4正在IFU中取指令, 两者都需要读内存; 在T5时刻, I1正在WBU中写寄存器, I4正在IDU中读寄存器, 两者都需要访问寄存器堆

```
           T1   T2   T3   T4   T5   T6   T7   T8
         +----+----+----+----+----+
I1: lw   | IF | ID | EX | LS | WB |
         +----+----+----+----+----+
              +----+----+----+----+----+
I2: add       | IF | ID | EX | LS | WB |
              +----+----+----+----+----+
                   +----+----+----+----+----+
I3: sub            | IF | ID | EX | LS | WB |
                   +----+----+----+----+----+
                        +----+----+----+----+----+
I4: xor                 | IF | ID | EX | LS | WB |
                        +----+----+----+----+----+
```

部分结构冒险可以从硬件设计上完全避免, 使其不会在CPU执行过程中发生: 我们只需要在硬件设计上让这些部件支持同时被多个阶段访问即可. 具体地:

- 对于寄存器堆, 我们只需要独立实现其读口和写口, 让IDU通过读口访问寄存器堆, 让WBU通过写口访问寄存器堆
- 对于内存, 则有多种解决方案
    - 像寄存器堆那样将读口和写口分开, 实现真双口的内存
    - 将内存分为指令存储器和数据存储器, 两者独立工作
    - 引入cache, 如果在cache中命中, 则无需访问内存

事实上, SDRAM的存储颗粒无法将读口跟写口分开, 无论是READ命令还是WRITE命令, 都是通过SDRAM的存储器总线传递给SDRAM颗粒. 而将内存分为指令存储器和数据存储器, 将会使得指令和数据位于不同的地址空间, 这违反了ISA规范对指令和数据采用统一地址空间的内存模型

有一些结构冒险还是无法完全避免, 例如:

- cache缺失时, IFU和LSU还是要同时访问内存
- SDRAM控制器的队列满了, 无法继续接收请求
- 除法器的计算需要花数十个周期, 在一次计算结束之前无法开始另一次

为了应对上述情况, 一种简单的处理方式是等待: 如果IFU和LSU同时访存, 就让一个等待另一个, 事实上通过一层仲裁逻辑把优先访问权给lsu. 如果让 lsu 等待 ifu, 可能会出现: lsu 修改了某一条指令, id/ex 有一条 fence.i, ifu 取的指令恰好为 lsu 将要保存的指令, 此时将会取到旧指令, 发生错误

### 数据冒险
数据冒险是指不同阶段的指令依赖同一个寄存器数据, 且至少有一条指令写入该寄存器. 例如, 在下图所示的指令序列中, I1要写a0寄存器, 但要在T5时刻结束时才完成写入, 在这之前, I2在T3时刻读到a0的旧值, I3在T4时刻读到a0的旧值, I4在T5时刻读到a0的旧值, I5在T6时刻才能读到a0的新值

```
                    T1   T2   T3   T4   T5   T6   T7   T8   T9
                  +----+----+----+----+----+
I1: add a0,t0,s0  | IF | ID | EX | LS | WB |
                  +----+----+----+----+----+
                       +----+----+----+----+----+
I2: sub a1,a0,t0       | IF | ID | EX | LS | WB |
                       +----+----+----+----+----+
                            +----+----+----+----+----+
I3: and a2,a0,s0            | IF | ID | EX | LS | WB |
                            +----+----+----+----+----+
                                 +----+----+----+----+----+
I4: xor a3,a0,t1                 | IF | ID | EX | LS | WB |
                                 +----+----+----+----+----+
                                      +----+----+----+----+----+
I5: sll a4,a0,1                       | IF | ID | EX | LS | WB |
                                      +----+----+----+----+----+
```

上述数据冒险称为写后读(Read After Write, RAW)冒险, RAW冒险的特征是, 一条指令需要写入某寄存器, 而另一条更年轻的指令需要读出该寄存器. 显然, 如果不处理这种数据冒险, 指令I2, I3和I4将会因为读到a0的旧值而计算出错误的结果, 违反指令执行的语义

解决RAW冒险有多种方式. 从软件上来看, 指令是由编译器生成的, 因此一种方式是让编译器来检测RAW冒险, 并插入空指令, 来等待写入寄存器的指令完成写入, 如下图所示:

```
                    T1   T2   T3   T4   T5   T6   T7   T8   T9   T10  T11  T12
                  +----+----+----+----+----+
I1: add a0,t0,s0  | IF | ID | EX | LS | WB |
                  +----+----+----+----+----+
                       +----+----+----+----+----+
    nop                | IF | ID | EX | LS | WB |
                       +----+----+----+----+----+
                            +----+----+----+----+----+
    nop                     | IF | ID | EX | LS | WB |
                            +----+----+----+----+----+
                                 +----+----+----+----+----+
    nop                          | IF | ID | EX | LS | WB |
                                 +----+----+----+----+----+
                                      +----+----+----+----+----+
I2: sub a1,a0,t0                      | IF | ID | EX | LS | WB |
                                      +----+----+----+----+----+
                                           +----+----+----+----+----+
I3: and a2,a0,s0                           | IF | ID | EX | LS | WB |
                                           +----+----+----+----+----+
                                                +----+----+----+----+----+
I4: xor a3,a0,t1                                | IF | ID | EX | LS | WB |
                                                +----+----+----+----+----+
                                                     +----+----+----+----+----+
I5: sll a4,a0,1                                      | IF | ID | EX | LS | WB |
                                                     +----+----+----+----+----+
```

插入空指令的本质还是等待, 但其实编译器还可以做得更好: 与其等待, 还不如执行一些有意义的指令. 这可以通过让编译器进行指令调度的工作来实现, 编译器可以尝试寻找一些没有数据依赖关系的指令, 在不影响程序行为的情况下调整其顺序. 一个例子如下, 其中I6, I7和I8均与I1无数据依赖关系, 因此可以调度到I1之后执行:

```
I1: add a0,t0,s0          I1: add a0,t0,s0
I2: sub a1,a0,t0          I6: add t5,t4,t3
I3: and a2,a0,s0          I7: add s5,s4,s3
I4: xor a3,a0,t1   --->   I8: sub s6,t4,t2
I5: sll a4,a0,1           I2: sub a1,a0,t0
I6: add t5,t4,t3          I3: and a2,a0,s0
I7: add s5,s4,s3          I4: xor a3,a0,t1
I8: sub s6,t4,t2          I5: sll a4,a0,1
```

不过对于指令调度的工作, 编译器只能尽力而为, 并非总能找到合适的指令. 例如, 除法指令需要执行数十个周期, 编译器通常很难找到这么多合适的指令. 在这些情况下, 如果要让编译器来处理RAW冒险, 还是只能插入空指令.

有的RAW光靠编译器是无法解决的. 考虑被依赖的指令是一条load指令, 这种RAW冒险称为load-use冒险:

```
                    T1   T2   T3  ....  T?   T?   T?   T?   T?   T?   T?
                  +----+----+----+--------------+----+
I1: lw  a0,t0,s0  | IF | ID | EX |      LS      | WB |
                  +----+----+----+--------------+----+
                       +----+----+----+----+----+
    nop X ?            | IF | ID | EX | LS | WB |
                       +----+----+----+----+----+
                                                +----+----+----+----+----+
I2: sub a1,a0,t0                                | IF | ID | EX | LS | WB |
                                                +----+----+----+----+----+
```

事实上, 在真实的SoC中, 软件几乎无法预测一条访存指令在将来执行时的延迟:

- 如果cache命中, 数据可能3个周期后返回
- 如果cache缺失, 要访问SDRAM, 数据可能30个周期后返回
- 如果正好碰上SDRAM充电刷新, 数据可能30+?个周期后返回
- 如果CPU频率从500MHz提升到600MHz, 数据返回所需的周期数更多

也因为这样, 现代处理器几乎都采用硬件检测并处理RAW冒险的方案. 由于寄存器的写入操作发生在WBU中, 因此需要写入的寄存器编号会也会随着流水线传播到WBU, 也即, 我们可以从每个阶段中找到相应指令将要写入哪一个寄存器. 如果位于IDU的指令要读出的寄存器与后续某阶段中将要写入的寄存器相同, 则发生RAW冒险. 实际上还需要考虑更多的问题: 并非所有指令都需要写入寄存器, 并非所有阶段都正在执行指令, 并非所有指令都需要读出rs2(如U型指令), 零寄存器的值恒为0等

检测到RAW冒险后, 最简单的处理方式还是等待: 只要把 in.ready 和 out.valid 置为无效即可. 可见, 这种硬件检测和处理RAW冒险的方案, 无需提前得知指令执行何时结束, 这是因为指令执行过程中的各种等待都会通过总线的握手信号传递到流水线当中, 因此适用性比上述的软件方案更强

### 控制冒险
控制冒险是指跳转指令会改变指令执行顺序, 导致IFU可能会取到不该执行的指令. 例如, 在下图所示的指令序列中, T4的IFU具体应该取出哪条指令, 需要等到I3在T5时刻计算出跳转结果后才能得知.

```
                 T1   T2   T3   T4   T5   T6   T7   T8
               +----+----+----+----+----+
I1: 100   add  | IF | ID | EX | LS | WB |
               +----+----+----+----+----+
                    +----+----+----+----+----+
I2: 104   lw        | IF | ID | EX | LS | WB |
                    +----+----+----+----+----+
                         +----+----+----+----+----+
I3: 108   beq 200        | IF | ID | EX | LS | WB |
                         +----+----+----+----+----+
                              +----+----+----+----+----+
I4: ???   ???                 | IF | ID | EX | LS | WB |
                              +----+----+----+----+----+
```

除了上述分支指令, `jal` 和 `jalr` 也会造成类似问题. 假设上图的I3为跳转指令, 我们期望在T4时刻就取出跳转目标处的指令, 而在T4时刻IDU正好在对I3进行译码, 按道理是可以赶上的, 但现代处理器一般会认为还是赶不上, 从而将其作为控制冒险来处理

问题都是因为在取指阶段无法确定接下来真正需要取出哪条指令. 如果选择等待, 就要等待上一条指令几乎执行完成, 才能得知下一条指令的真正地址. 例如, 访存指令要等到访存结束后, 通过总线的resp信号才能确定访存过程没有抛出异常. 显然, 这个方案会使得指令流水线流不起来, 大幅降低处理器执行指令的吞吐. 而如果选择不等待, 就有可能取出了一部分不该执行的指令, 如果不采取进一步的处理措施, 处理器的状态转移就会与ISA状态机不一致, 从而导致执行结果不正确

为了应对控制冒险, 现代处理器通常采用"推测执行"(speculative execution)的技术. 推测执行本质上是一种预测技术, 其基本思想是, 在等待的同时尝试推测一个选择, 如果猜对了, 就相当于提前做出了正确的选择, 从而节省了等待的开销. 推测执行具体由三部分组成:

- 选择策略: 得到正确结果之前, 通过一定的策略推测一个选择
- 检查机制: 得到正确结果时, 检查之前推测的选择是否与正确结果一致
- 错误恢复: 如果检查后发现不一致, 则需要回滚到选择策略时的状态, 并根据得到的正确结果做出正确的选择

#### 最简单的, 总是推测接下来执行下一条静态指令

- 选择策略: 让IFU一直取出 `PC + 4` p处的指令即可.
- 检查机制: 根据指令的语义, 只有在执行分支和跳转指令, 以及抛出异常时, CPU才有可能改变执行流, 其他情况下都是顺序执行. 因而在其他情况下, 上述推测的选择总是正确的, 无需额外检查. 故只需要在执行分支和跳转指令, 以及抛出异常时, 才需要检查跳转结果与推测的选择是否一致, 也即, 检查跳转结果是否为 `PC + 4`
- 错误恢复: 如果发现上述跳转结果不为 `PC + 4`, 则说明之前的推测是错误的, 基于这一推测所取出的指令都不应该被执行, 应该将其从流水线上消除, 这一动作称为"冲刷"; 同时还需要让IFU从正确的跳转结果处取指

推测执行所带来的性能提升与推测的准确率有关, 如果推测的准确率高, 则IFU能以高概率提前取到正确的指令, 从而节省等待的开销; 如果推测的准确率低, 则IFU经常取到不该执行的指令, 这些指令后续又被冲刷, 在这段时间内, 流水线的行为等价于未执行任何有效指令, 从而降低了执行指令的吞吐. 具体地:

- 由于异常属于处理器执行过程中的小概率事件, 绝大部分指令的执行都不会抛出异常, 因此针对异常, 上述策略的准确率接近100%
- 分支指令的执行结果只有"跳转"(taken)和"不跳转"(not taken), 上述策略相当于总是预测"不跳转", 因此从概率上来说, 针对分支指令, 上述策略的准确率接近50%
- 跳转指令的行为是无条件跳转到目标地址, 但目标地址的可能有很多, 正好跳转到 `PC + 4` 的概率非常低, 因此针对跳转指令, 上述策略的准确率接近0%

根据上述分析, 推测执行一方面可以正确处理控制冒险, 另一方面, 相对于消极等待的方式, 推测执行还可以带来一定的性能提升. 但针对分支指令和跳转指令, 上述的推测执行方案还有较大的提升空间, 我们会在下文继续讨论.

关于推测执行的实现, 还有一些需要注意的细节:

- 从需求的角度来看, 冲刷是为了将处理器的状态恢复成发生控制冒险之前的时刻, 因此, 我们可以从状态机的视角推导出应该如何处理相关的实现细节. 状态机视角告诉我们, 处理器的状态由时序逻辑电路决定, 而处理器的状态更新又受到控制信号的控制, 因此, 要实现冲刷的效果, 我们只需要考虑将相关的控制信号置为无效即可. 例如, 通过将valid置为无效, 可以将大部分部件正在执行的指令直接冲刷掉.
- 但如果部件中还存在一些影响控制信号的状态, 你还需要进行额外的考量, 例如icache中的状态机, 尤其是发出的AXI请求无法撤回, 因此需要等待请求完成.
- 推测执行意味着当前执行的操作不一定是将来真正需要的, 如果推测错误, 就应该取消相关操作. 但有一些操作很难取消, 包括更新寄存器堆, 更新CSR, 写内存, 访问外设等, 这些模块的状态一旦发生改变, 就很难恢复到旧状态. 因此, 需要在确认推测正确后, 才能更新这些模块的状态